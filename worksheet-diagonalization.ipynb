{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64a32145",
   "metadata": {},
   "source": [
    "# Eigenvalues and diagonalization\n",
    "\n",
    "Let $A$ be a symmetric matrix. According to the [real spectral theorem](https://opentext.uleth.ca/Math3410/subsec-ortho-diag.html#thm-real-spectral), there exists an orthogonal matrix $P$ such that $P^TAP$ is diagonal, with the entries on the main diagonal given by the eigenvalues of $A$.\n",
    "\n",
    "In this worksheet, we will work through the process of finding the eigenvalues of a symmetric matrix, along with the orthogonal matrix $P$.\n",
    "\n",
    "We will also look at the method described in [Section 4.6](https://opentext.uleth.ca/Math3410/section-matrix-factor.html#pars-power-method) for finding dominant eigenvalues.\n",
    "\n",
    "## Orthogonal diagonalization\n",
    "\n",
    "Consider the following $5\\times 5$ matrix $A$:\n",
    "\n",
    "$$A = \\begin{bmatrix}97&-23&-23&-3&-46\\\\-23&49&1&21&2\\\\-23&1&49&21&2\\\\-3&21&21&9&42\\\\-46&2&2&42&52\\end{bmatrix}$$\n",
    "\n",
    "First, let's enter the matrix and confirm that it's symmetric. You can compute the transpose of a SymPy matrix `A` using `A.T`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f230c9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import Matrix, init_printing\n",
    "init_printing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc21a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8ec410e",
   "metadata": {},
   "source": [
    "Now, let's find the eigenvalues of $A$. Yes, there's a way to jump straight to the answer, but let's go through the steps anyway. First, compute the characteristic polynomial of $A$. You may wish to refer to the [appendix on SymPy](https://opentext.uleth.ca/Math3410/sec-sympy.html#subsec-sympy-matrix-20) in the textbook for details on the correct syntax to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df3c23e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02054947",
   "metadata": {},
   "source": [
    "Now, factor the polynomial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeed0fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da1dc16c",
   "metadata": {},
   "source": [
    "Finally, based on the result above, input the eigenvalues into the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dfd78e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "685cb10b",
   "metadata": {},
   "source": [
    "Now, recall that the if $\\vec{v}$ is an eigenvector of $A$ corresponding to the eigenvalue $\\lambda$, then $\\vec{v}$ belongs to the nullspace of $\\lambda I - A$, where $I$ is the identity matrix. You can create an $n\\times n$ identity matrix in SymPy using the syntax `eye(n)`.\n",
    "\n",
    "For each eigenvalue $\\lambda$ found above, compute the nullspace of $\\lambda I-A$. You will want to refer to these nullspaces later, so give each one a name. For example, if your first eigenvalue was 7, you could enter something like \n",
    "```\n",
    "E1 = (7*eye(5)-A).nullspace()\n",
    "E1\n",
    "```\n",
    "to get the first eigenspace. Three code cells are provided below; if you need more, click on the $+$ button in the toolbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928262e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc57474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c211e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e221aef",
   "metadata": {},
   "source": [
    "Now, let's check our work. Use the command `A.eigenvects()` to compute the eigenvectors and eigenvalues in one step, and confirm that the results match what you found above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715a3027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82d9cf88",
   "metadata": {},
   "source": [
    "Next, we want to diagonalize $A$. There is a `diagonalize` command, but it won't do *orthogonal* diagonalization, which is what we want.\n",
    "\n",
    "Recall that the eigenvectors corresponding to *distinct* eigenvalues are automatically orthogonal. But this is not true of *repeated* eigenvalues, and there's a good chance you've found that one of your eigenvalues has multiplicity greater than 1.\n",
    "\n",
    "A matrix $P$ is orthogonal if $P^TP=I$, in which case the columns of $P$ form an *orthonormal* basis. (So we are looking for an orthonormal basis of eigenvectors.)\n",
    "\n",
    "For any 1-dimensional eigenspaces, you will just need to find a unit eigenvector. For example, if $\\vec{v}=(2,1,0,3,1)$ is an eigenvector for an eigenvalue of multiplicity 1, then you will want to use the eigenvector $\\vec{u} = \\frac{1}{\\sqrt{15}}(2,1,0,3,1)$, since $\\lVert \\vec{v}\\rVert = \\sqrt{15}$.\n",
    "\n",
    "For any higher-dimensional eigenspaces, you can use the Gram-Schmidt algorithm. Recall that the optional argument `true` will produce unit vectors: given a basis `B` for an eigenspace, the command `GramSchmidt(B,true)` will produce an orthonormal basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c5011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import GramSchmidt, sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3eb7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55320691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f577150",
   "metadata": {},
   "source": [
    "Once you have found five orthonormal eigenvectors, create a matrix $P$ whose columns are those eigenvectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048524d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af5e24bd",
   "metadata": {},
   "source": [
    "Confirm that your matrix is orthogonal by computing $PP^T$. You should get the identity matrix as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f10e12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc592152",
   "metadata": {},
   "source": [
    "Finally, compute the matrix $P^TAP$, and confirm that the result is a diagonal matrix whose entries are the eigenvalues of $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e12051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fd2bb36",
   "metadata": {},
   "source": [
    "## The power method for dominant eigenvalues\n",
    "\n",
    "For the problem you just completed, you may have noticed that there was one eigenvalue that was larger in absolute value than all the other eigenvalues. Such an eigenvalue is called a **dominant eigenvalue**.\n",
    "\n",
    "If you complete the [worksheet on linear dynamical systems](https://opentext.uleth.ca/Math3410/worksheet-dynamical.html), you will see that the state of such systems is ultimately given by a sum of certain geometric series (involving eigenvalues of a matrix), and that the long-term behaviour of the system is approximately geometric, and governed by the dominant eigenvalue.\n",
    "\n",
    "The power method states that, given an initial state vector $\\vec{x}_0$, the sequence of vectors\n",
    "$$\\vec{x}_0,A\\vec{x}_0,A^2\\vec{x}_0,\\ldots, A^k\\vec{x}_0,\\ldots$$\n",
    "will converge to an eigenvector for the dominant eigenvalue.\n",
    "\n",
    "Let's see if this is true. Below, you are given an initial guess `x0` and an empty list `L`. You want to populate `L` with vectors of the form $A^k\\vec{x}_0$, for $0\\leq k\\leq 10$. This is most easily done using a `for` loop. For details on syntax, see the [example in the textbook](https://opentext.uleth.ca/Math3410/section-matrix-factor.html#pars-power-method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef92b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = Matrix([1,0,1,0,1])\n",
    "L = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf7706c",
   "metadata": {},
   "source": [
    "Let's print the last vector in the list, which will probably have some pretty big entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0dfe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "L[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7859bca6",
   "metadata": {},
   "source": [
    "Now let's check our work.\n",
    "\n",
    "How can we tell if this vector is (approximately) a multiple of the dominant eigenvector? One option is to divide each entry in `L[10]` by the smallest (in absolute value) non-zero entry in `L[10]`. How does this compare to the eigenvector you originally found for the dominant eigenvalue?\n",
    "\n",
    "If you find that some entries look right, but not others, see the end of the worksheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c585f0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06a29ed4",
   "metadata": {},
   "source": [
    "Finally, suppose we didn't know what the dominant eigenvalue was, and we wanted to find it.\n",
    "\n",
    "Note that if $\\vec{x}$ is a dominant eigenvector, then $A\\vec{x} = \\lambda\\vec{x}$, where $\\lambda$ is the dominant eigenvalue. Then\n",
    "\n",
    "$$\\lambda = \\frac{\\vec{x}\\cdot (\\lambda\\vec{x})}{\\vec{x}\\cdot \\vec{x}} = \\frac{\\vec{x}\\cdot A\\vec{x}}{\\vec{x}\\cdot \\vec{x}}.$$\n",
    "\n",
    "It seems reasonable, then, that if $\\vec{x}_k$ is *approximately* equal to a dominant eigenvector, then the numbers\n",
    "\n",
    "$$r_k = \\frac{\\vec{x}x_k\\cdot A\\vec{x}_k}{\\vec{x}_k\\cdot \\vec{x}_k}=\\frac{\\vec{x}_k\\cdot \\vec{x}_{k+1}}{\\lVert \\vec{x}_k\\rVert^2}$$\n",
    "\n",
    "should be approximately equal to the dominant eigenvalue. (These numbers are the so-called *Rayliegh quotients*.)\n",
    "\n",
    "Following the approach [given in the textbook](https://opentext.uleth.ca/Math3410/section-matrix-factor.html#pars-power-method-10), compute the Rayleigh quotients $r_k$ for $1\\leq k\\leq 10$, and comment on how well they approximate the dominant eigenvalue of $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e30e886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5130bd3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46e16001",
   "metadata": {},
   "source": [
    "Does it look like the numbers are approaching the dominant eigenvalue? Or do they seem to be getting near one of the other eigenvalues?\n",
    "\n",
    "If your numbers seem wrong, it might be for the following reason: when we write our initial guess `x0` as a linear combination of the eigenvectors, the coefficient of the dominant eigenvector has to be nonzero. Is that the case here? To check, note that if $\\vec{c}$ is the vector of coefficients, then we must have $P\\vec{c}=\\vec{x}_0$. Can you solve this equation for $\\vec{c}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870195c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13dedbac",
   "metadata": {},
   "source": [
    "If the first entry in `c` is zero, enter a new value for `x0`, and try the above steps again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5992d16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
