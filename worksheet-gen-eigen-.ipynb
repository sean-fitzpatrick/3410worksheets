{
"cells": [
{"cell_type":    "code", "execution_count":null, "metadata":{}, "source":["%%html\n<link href=\"https:\/\/pretextbook.org\/beta\/mathbook-content.css\" rel=\"stylesheet\" type=\"text\/css\" \/>\n<link href=\"https:\/\/aimath.org\/mathbook\/mathbook-add-on.css\" rel=\"stylesheet\" type=\"text\/css\" \/>\n<link href=\"https:\/\/fonts.googleapis.com\/css?family=Open+Sans:400,400italic,600,600italic\" rel=\"stylesheet\" type=\"text\/css\" \/>\n<link href=\"https:\/\/fonts.googleapis.com\/css?family=Inconsolata:400,700&subset=latin,latin-ext\" rel=\"stylesheet\" type=\"text\/css\" \/><!-- Hide this cell. -->\n<script>\nvar cell = $(\".container .cell\").eq(0), ia = cell.find(\".input_area\")\nif (cell.find(\".toggle-button\").length == 0) {\nia.after(\n    $('<button class=\"toggle-button\">Toggle hidden code<\/button>').click(\n        function (){ ia.toggle() }\n        )\n    )\nia.hide()\n}\n<\/script>\n"], "outputs":[]},
{"cell_type":"markdown", "metadata":{}, "source":["**Important:** to view this notebook properly you will need to execute the cell above, which assumes you have an Internet connection.  It should already be selected, or place your cursor anywhere above to select.  Then press the \"Run\" button in the menu bar above (the right-pointing arrowhead), or press Shift-Enter on your keyboard."]},
{"cell_type":"markdown", "metadata":{}, "source":["$\\newcommand{\\spn}{\\operatorname{span}}\n\\newcommand{\\bbm}{\\begin{bmatrix}}\n\\newcommand{\\ebm}{\\end{bmatrix}}\n\\newcommand{\\R}{\\mathbb{R}}\n\\renewcommand{\\C}{\\mathbb{C}}\n\\newcommand{\\im}{\\operatorname{im}}\n\\newcommand{\\nll}{\\operatorname{null}}\n\\newcommand{\\csp}{\\operatorname{col}}\n\\newcommand{\\rank}{\\operatorname{rank}}\n\\newcommand{\\diag}{\\operatorname{diag}}\n\\newcommand{\\tr}{\\operatorname{tr}}\n\\newcommand{\\dotp}{\\!\\boldsymbol{\\cdot}\\!}\n\\newcommand{\\len}[1]{\\lVert #1\\rVert}\n\\newcommand{\\abs}[1]{\\lvert #1\\rvert}\n\\newcommand{\\proj}[2]{\\operatorname{proj}_{#1}{#2}}\n\\newcommand{\\bz}{\\overline{z}}\n\\newcommand{\\zz}{\\mathbf{z}}\n\\newcommand{\\uu}{\\mathbf{u}}\n\\newcommand{\\vv}{\\mathbf{v}}\n\\newcommand{\\ww}{\\mathbf{w}}\n\\newcommand{\\xx}{\\mathbf{x}}\n\\newcommand{\\yy}{\\mathbf{y}}\n\\newcommand{\\zer}{\\mathbf{0}}\n\\newcommand{\\vecq}{\\mathbf{q}}\n\\newcommand{\\vecp}{\\mathbf{p}}\n\\newcommand{\\vece}{\\mathbf{e}}\n\\newcommand{\\basis}[2]{\\{\\mathbf{#1}_1,\\mathbf{#1}_2,\\ldots,\\mathbf{#1}_{#2}\\}}\n\\newcommand{\\gt}{>}\n\\newcommand{\\amp}{&}\n$"]}Worksheet 5.4 Worksheet: generalized eigenvectorsA4US{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><div class=\"introduction\" id=\"introduction-17\"><p id=\"p-880\">Let $V$ be a finite-dimensional vector space, and let $T:V\\to V$ be a linear operator. Assume that $T$ has all real eigenvalues (alternatively, assume we're working over the complex numbers). Let $A$ be the matrix of $T$ with respect to some standard basis $B_0$ of $V\\text{.}$<\/p><p id=\"p-881\">Our goal will be to replace the basis $B_0$ with a basis $B$ such that the matrix of $T$ with respect to $B$ is as simple as possible. (Where we agree that the \"simplest\" possible matrix would be diagonal.)<\/p><p id=\"p-882\">Recall the following results that we've observed so far:<\/p><ul class=\"disc\"><li id=\"li-152\"><p id=\"p-883\">The characteristic polynomial $c_T(x)$ of $T$ does not depend on the choice of basis.<\/p><\/li><li id=\"li-153\"><p id=\"p-884\">The eigenvalues of $T$ are the roots of this polynomial.<\/p><\/li><li id=\"li-154\"><p id=\"p-885\">The eigenspaces $E_\\lambda(T)$ are $T$-invariant subspaces of $V\\text{.}$<\/p><\/li><li id=\"li-155\"><p id=\"p-886\">The matrix $A$ can be diagonalized if and only if there is a basis of $V$ consisting of eigenvectors of $T\\text{.}$<\/p><\/li><li id=\"li-156\"><p id=\"p-887\">Suppose<\/p><div xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"displaymath process-math\">\n\\begin{equation*}\nc_T(x) = (x-\\lambda_1)^{m_1}(x-\\lambda_2)^{m_2}\\cdots (x-\\lambda_k)^{m_k}\\text{.}\n\\end{equation*}\n<\/div><p class=\"continuation\">Then $A$ can be diagonalized if and only if $\\dim E_{\\lambda_i}(T) = m_i$ for each $i=1,\\ldots, k\\text{.}$<\/p><\/li><\/ul><p id=\"p-888\">In the case where $A$ can be diagonalized, we have the direct sum decomposition<\/p><div class=\"displaymath process-math\">\n\\begin{equation*}\nV = E_{\\lambda_1}(T)\\oplus E_{\\lambda_2}(T) \\oplus \\cdots \\oplus E_{\\lambda_k}(T)\\text{.}\n\\end{equation*}\n<\/div><p id=\"p-889\">The question is: what do we do if there aren't enough eigenvectors to form a basis of $V\\text{?}$ When that happens, the direct sum of all the eigenspaces will not give us all of $V\\text{.}$<\/p><p id=\"p-890\">The idea: replace $E_{\\lambda_j}(T)$ with a <dfn class=\"terminology\">generalized eigenspace<\/dfn> $G_{\\lambda_j}(T)$ whose dimension is $m_i\\text{.}$<\/p><p id=\"p-891\">Our candidate: instead of $E_{\\lambda}(T) = \\ker(T-\\lambda I)\\text{,}$ we use $G_\\lambda(T) = \\ker((T-\\lambda I)^m)\\text{,}$ where $m$ is the multiplicity of $\\lambda\\text{.}$<\/p><\/div><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"exercise exercise-like\" id=\"ws-ge-ex1\"><h3 class=\"heading\"><span class=\"codenumber\">1<span xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"period\">.<\/span><\/span><\/h3><p id=\"p-892\">Recall that in class we proved that $\\ker(T)$ and $\\operatorname{im}(T)$ are $T$-invariant subspaces. Let $p(x)$ be any polynomial, and prove that $\\ker (p(T))$ and $\\operatorname{im}(p(T))$ are also $T$-invariant.<\/p><p id=\"p-893\"><em class=\"emphasis\">Hint:<\/em> first show that $p(T)T=Tp(T)$ for any polynomial $T\\text{.}$<\/p><div class=\"workspace\" data-space=\"3in\" \/><\/article><\/div>"]},
{"cell_type":    "code", "execution_count":null, "metadata":{}, "source":[""], "outputs":[]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-894\">Applying the result of Problem 1 to the polynomial $p(x) = (x-\\lambda)^m$ shows that $G_\\lambda(T)$ is $T$-invariant. It is possible to show that $\\dim G_\\lambda(T)=m$ but I won't ask you to do that. (A proof is in Nicholson if you really want to see it.)<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-895\">Instead, we will try to understand what's going on by exploring an example.<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-896\">Consider the following matrix.<\/p><\/div>"]},
{"cell_type":    "code", "execution_count":null, "metadata":{}, "source":["from sympy import *\ninit_printing()\nA=Matrix([[2,0,0,1,0],[-1,0,1,2,3],[0,1,2,0,-1],[-2,-3,2,5,3],[0,-1,0,1,4]])\nA"], "outputs":[]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"exercise exercise-like\" id=\"ws-ge-ex2\"><h3 class=\"heading\"><span class=\"codenumber\">2<span xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"period\">.<\/span><\/span><\/h3><p id=\"p-897\">Find (and factor) the characteristic polynomial of $A\\text{.}$ For the commands you might need, <a class=\"external\" href=\"https:\/\/opentext.uleth.ca\/Math3410\/sec-sympy.html\" target=\"_blank\">refer to the textbook<\/a>.<\/p><div class=\"workspace\" data-space=\"2in\" \/><\/article><\/div>"]},
{"cell_type":    "code", "execution_count":null, "metadata":{}, "source":[""], "outputs":[]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"exercise exercise-like\" id=\"ws-ge-ex3\"><h3 class=\"heading\"><span class=\"codenumber\">3<span xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"period\">.<\/span><\/span><\/h3><p id=\"p-898\">Find the eigenvectors. What are the dimensions of the eigenspaces? Based on this observation, can $A$ be diagonalized?<\/p><div class=\"workspace\" data-space=\"3.25in\" \/><\/article><\/div>"]},
{"cell_type":    "code", "execution_count":null, "metadata":{}, "source":[""], "outputs":[]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"exercise exercise-like\" id=\"ws-ge-ex4\"><h3 class=\"heading\"><span class=\"codenumber\">4<span xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"period\">.<\/span><\/span><\/h3><p id=\"p-899\">Prove that for any $n\\times n$ matrix $A\\text{,}$ we have<\/p><div class=\"displaymath process-math\">\n\\begin{equation*}\n\\{0\\}\\subseteq \\operatorname{null}(A)\\subseteq \\operatorname{null}(A^2) \\subseteq \\cdots \\subseteq \\operatorname{null}(A^n)\\text{.}\n\\end{equation*}\n<\/div><div class=\"workspace\" data-space=\"3.25in\" \/><\/article><\/div>"]},
{"cell_type":    "code", "execution_count":null, "metadata":{}, "source":[""], "outputs":[]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-900\">It turns out that at some point, the null spaces stabilize. If $\\operatorname{null}(A^k)=\\operatorname{null}A^{k+1}$ for some $k\\text{,}$ then $\\operatorname{null}(A^k)=\\operatorname{null}(A^{k+l})$ for all $l\\geq 0\\text{.}$<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"exercise exercise-like\" id=\"ws-ge-ex5\"><h3 class=\"heading\"><span class=\"codenumber\">5<span xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"period\">.<\/span><\/span><\/h3><p id=\"p-901\">For each eigenvalue found in <a href=\"worksheet-gen-eigen.ipynb#ws-ge-ex2\" class=\"internal\" title=\"Worksheet Exercise 5.4.2\">Worksheet Exercise 5.4.2<\/a>, compute the nullspace of $A-\\lambda I\\text{,}$ $(A-\\lambda I)^2\\text{,}$ $(A-\\lambda I)^3\\text{,}$ etc. until you find two consecutive nullspaces that are the same.<\/p><p id=\"p-902\">By <a href=\"worksheet-gen-eigen.ipynb#ws-ge-ex4\" class=\"internal\" title=\"Worksheet Exercise 5.4.4\">Worksheet Exercise 5.4.4<\/a>, any vector in $\\operatorname{null}(A-\\lambda I)^m$ will also be a vector in $\\operatorname{null}(A-\\lambda I)^{m+1}\\text{.}$ In particular, at each step, we can find a basis for $\\operatorname{null}(A-\\lambda I)^m$ that includes the basis for $\\operatorname{null}(A-\\lambda I)^{m-1}\\text{.}$<\/p><p id=\"p-903\">For each eigenvalue found in <a href=\"worksheet-gen-eigen.ipynb#ws-ge-ex2\" class=\"internal\" title=\"Worksheet Exercise 5.4.2\">Worksheet Exercise 5.4.2<\/a>, determine such a basis for the corresponding generalized eigenspace. You will want to list your vectors so that the vectors from the basis of the nullspace for $A-\\lambda I$ come first, then the vectors for the basis of the nullspace for $(A-\\lambda I)^2\\text{,}$ and so on.<\/p><div class=\"workspace\" data-space=\"2.5in\" \/><\/article><\/div>"]},
{"cell_type":    "code", "execution_count":null, "metadata":{}, "source":[""], "outputs":[]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"exercise exercise-like\" id=\"ws-ge-ex6\"><h3 class=\"heading\"><span class=\"codenumber\">6<span xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"period\">.<\/span><\/span><\/h3><p id=\"p-904\">Finally, let's see how all of this works. Let $P$ be the matrix whose columns consist of the vectors found in Problem 4. What do you get when you compute the matrix $P^{-1}AP\\text{?}$<\/p><div class=\"workspace\" data-space=\"2.5in\" \/><\/article><\/div>"]},
{"cell_type":    "code", "execution_count":null, "metadata":{}, "source":[""], "outputs":[]}
],
"nbformat": 4, "nbformat_minor": 0, "metadata": {"kernelspec": {"display_name": "", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}, "name": "worksheet-gen-eigen-.ipynb"}
}